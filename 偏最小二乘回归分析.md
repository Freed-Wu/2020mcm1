
### 偏最小二乘回归分析
在实际问题中，经常遇到两组多重变量间的相互依赖关系，用一组变量去预测另一组变量，除了最小二乘准则下的景点多元线性回归分析（MLR)，提取自变量主成分的主成分方法PCR,还有PLS.
继承了主成分分析和典型相关分析组合起来
#### 偏最小二乘回归分析的建模的具体分析
 1. 分别提取量变量组的第一队成分，并使之相关性最大
 2. 建立$ y_{1},\dots,y_{p}  $对t1回归及$ x_{1},\dots,x_{m} $对t1的回归
 3. 用残差阵$ E_{1}和F_{1} $代替 $ E_{0}和F_{0} $
 4. 设n * m的秩 $ r<= min(n-1,m) $,则存在r个成分$ t_{1},t_{2}, \dots $即可得到p个因变量的偏最小二乘回归方程
 5. 交叉有效性检验，一般情况下，偏最小二乘并不需要选用存在r个成分进行回归建模，选用前l个观测值，用最小二乘回归方法监控，对于所需要地区的成分个数可通过交叉检验有效性来决定。并考虑抽取h个城根后拟合的回归时，然后把程社区的第i个观测点代入所拟合的回归方程
 ### PCA方法的改进多余多重变针对单一因变量或者多元银边量进行讷河

```
clc,clear
mu=mean(pz);sg=std(pz);%计算均值和标准差
n=corrcoef(pz);
data=zscore(pz);%数据标准化
n=3;m=3;%n为自变量的个数,m为因电量的个数
x0=pz(:,1:n);y0=pz(:,n+1:end)%原始的自变量和因变量的数据
e0=data(:,1:n);f0=data(:,n+1:end);%标准化后的自变量和因变量的数据
num=size(e0,1)%求样本点的个数
chg=eye(n);%w到w*变换矩阵的初始化
for i=1:n
    matrix=e0'*f0*f0'*e0
    [vec,val]=eig(matrix);%求特征值和特征向量
    val=diag(val)%提出对角线元素，即提出特征值
    [val,in]=sort(val,'descend');
    w(:,i)=vec(:,ind(1));%移除最大特征值对应的特征向量
    w_star(:,i)=chg*w(:,i);
    t(:,i)=e0*w(:,i);%计算成分ti的得分
    alpha=e0'*t(;,i)y
未完待续
```

1. 求数据标准化
2. 求相关系数矩阵
3. 分别提出自变量组和因变量组的成分
4. 求两个成分对是标准化指标变量与成分变量自检的回归方程
5. 求因变量组合自变量组的回归方程
```
clc,clear
mu=mean(x0);sig=std(ab0);
rr=corrcoef(ab0)%求相关系数矩阵
ab=zscore(ab0);数据表转化
a=ab(L,[1,3]);b=ab(:,[4:end]);%提出标准化后的自变量和因变量的数据
[XL,YL,XS,YS,BETA,PCTVAR,MSE,stats]=plsrefress(a,b);
contr=cumsum(pctvar,2);
xw=a\XS；
yw=b\XS;
ncomp=input('请根据PCTVAR提出对应的成分对的个数');
n=size(a,2);m=size(b,2);%分别为对应自变量和因变量的个数
[XL,YL,XS,YS,BETA,PCTVAR,MSE,stats]=plsrefress(a,b,ncomp);
beta3(1:)=mu(n+1:end)-mu(1:n)./sig(1:n)*BETA([2:end],:)*sig(n+1:end);%计算原始数据的回归方程
beta3([2:n+1],:)=(1./sig(1:n))'*sig(n+1:end).*BETA2([2:end],:)%求原始数据变量x1,....x2的系数
bar(BETA,'k')%画直方图
yhat=rempat(beta3(1,:),[size(a,1),1)+ab0(;,[1:n])*beta3([2:end],:);求解对应的预测值
ymax=max(pyhatlab0(;,[n+1:end]);
```

![image.png](最小二乘回归分析.jpg)
![image.png](pls.jpg)
